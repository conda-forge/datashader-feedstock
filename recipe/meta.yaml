{% set version = "0.8.0" %}

package:
  name: datashader
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/d/datashader/datashader-{{ version }}.tar.gz
  sha256: 59ac9e3830167d07b350992402a9f547f26eca45cd69a0fb04061a4047e7ff2a

build:
  number: 0
  noarch: python
  script: "{{ PYTHON }} -m pip install . --no-deps --ignore-installed --no-cache-dir -vvv"
  entry_points:
    - datashader = datashader.__main__:main

requirements:
  host:
    - python
    - pip
    - param >=1.6.1
    - pyct-core >=0.4.5
  run:
    - python >=2.7
    - bokeh
    - colorcet >=0.9.0
    - dask >=0.18.0
    - datashape >=0.5.1
    - numba >=0.37.0
    - numpy >=1.7
    - pandas >=0.20.3
    - param >=1.6.1
    - pillow >=3.1.1
    - pyct >=0.4.5
    - scikit-image
    - scipy
    - toolz >=0.7.4
    - xarray >=0.9.6

test:
  requires:
    - fastparquet >=0.1.6
    - flake8
    - nbsmoke >=0.2.6
    - pytest >=3.9.3
    - pytest-benchmark >=3.0.0
  imports:
    - datashader
  commands:
    - pytest --pyargs --doctest-modules --doctest-ignore-import-errors datashader
    - datashader copy-examples --path=. --force
    # just run one notebook for now; increase in the future if notebooks can be run quickly with test/tiny data
    - pytest --nbsmoke-run -k ".ipynb" getting_started/2_Pipeline.ipynb

about:
  home: http://datashader.org
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE.txt
  summary: 'Data visualization toolchain based on aggregating into a grid'
  description: |
    Datashader is a data rasterization pipeline for automating the process of
    creating meaningful representations of large amounts of data.
  doc_url: http://datashader.org
  dev_url: https://github.com/pyviz/datashader

extra:
  recipe-maintainers:
    - jbednar
    - ocefpaf
    - philippjfr
    - jsignell
